{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FDI6NKp2S_UF"
      },
      "outputs": [],
      "source": [
        "cython_code = \"\"\"\n",
        "import numpy as np\n",
        "cimport numpy as np\n",
        "from libc.math cimport INFINITY\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "cdef class CustomDecisionTreeClassifier:\n",
        "    cdef int max_depth\n",
        "    cdef object tree\n",
        "\n",
        "    def __init__(self, int max_depth=3):\n",
        "        self.max_depth = max_depth\n",
        "\n",
        "    def fit(self, X, y):\n",
        "        self.tree = self._build_tree(np.array(X, dtype=np.float32), np.array(y, dtype=np.int32))\n",
        "\n",
        "    cdef _build_tree(self, np.ndarray[np.float32_t, ndim=2] X, np.ndarray[np.int32_t, ndim=1] y, int depth=0):\n",
        "        if depth == self.max_depth or len(np.unique(y)) == 1:\n",
        "            return np.bincount(y).argmax()\n",
        "        cdef int best_feature\n",
        "        cdef float best_threshold\n",
        "        best_feature, best_threshold = self._find_best_split(X, y)\n",
        "        if best_feature == -1:\n",
        "            return np.bincount(y).argmax()\n",
        "\n",
        "        # Use native Python bool for indexing without explicitly defining the type\n",
        "        left_indices = X[:, best_feature] <= best_threshold\n",
        "        right_indices = X[:, best_feature] > best_threshold\n",
        "\n",
        "        cdef object left_tree = self._build_tree(X[left_indices], y[left_indices], depth + 1)\n",
        "        cdef object right_tree = self._build_tree(X[right_indices], y[right_indices], depth + 1)\n",
        "        return (best_feature, best_threshold, left_tree, right_tree)\n",
        "\n",
        "    cdef _find_best_split(self, np.ndarray[np.float32_t, ndim=2] X, np.ndarray[np.int32_t, ndim=1] y):\n",
        "        cdef int best_feature = -1\n",
        "        cdef float best_threshold = -1.0\n",
        "        cdef float best_gini = INFINITY\n",
        "        cdef int m = X.shape[0]\n",
        "        cdef int n = X.shape[1]\n",
        "        cdef int num_classes = len(np.unique(y))\n",
        "\n",
        "        cdef np.ndarray[np.int64_t, ndim=1] total_class_count = np.bincount(y, minlength=num_classes).astype(np.int64)\n",
        "        cdef np.ndarray[np.int64_t, ndim=1] left_class_count = np.zeros(num_classes, dtype=np.int64)\n",
        "        cdef np.ndarray[np.int64_t, ndim=1] right_class_count = total_class_count.copy()\n",
        "        cdef int total_left, total_right\n",
        "        cdef int i, feature, c\n",
        "        cdef float gini_left, gini_right, gini\n",
        "        cdef np.ndarray[np.int32_t, ndim=1] sorted_indices\n",
        "        cdef np.ndarray[np.float32_t, ndim=1] sorted_X\n",
        "        cdef np.ndarray[np.int32_t, ndim=1] sorted_y\n",
        "\n",
        "        for feature in range(n):\n",
        "            sorted_indices = np.argsort(X[:, feature]).astype(np.int32)\n",
        "            sorted_X = X[sorted_indices, feature]\n",
        "            sorted_y = y[sorted_indices]\n",
        "\n",
        "            left_class_count[:] = 0\n",
        "            right_class_count[:] = total_class_count\n",
        "            total_left = 0\n",
        "            total_right = m\n",
        "\n",
        "            for i in range(1, m):\n",
        "                c = sorted_y[i - 1]\n",
        "                left_class_count[c] += 1\n",
        "                right_class_count[c] -= 1\n",
        "                total_left += 1\n",
        "                total_right -= 1\n",
        "\n",
        "                if sorted_X[i] == sorted_X[i - 1]:\n",
        "                    continue\n",
        "\n",
        "                gini_left = 1.0 - np.sum((left_class_count / total_left) ** 2)\n",
        "                gini_right = 1.0 - np.sum((right_class_count / total_right) ** 2)\n",
        "                gini = (total_left * gini_left + total_right * gini_right) / m\n",
        "\n",
        "                if gini < best_gini:\n",
        "                    best_gini = gini\n",
        "                    best_feature = feature\n",
        "                    best_threshold = (sorted_X[i] + sorted_X[i - 1]) / 2\n",
        "\n",
        "        return best_feature, best_threshold\n",
        "\n",
        "    def predict(self, X):\n",
        "        return np.array([self._predict_sample(sample, self.tree) for sample in np.array(X, dtype=np.float32)])\n",
        "\n",
        "    cdef _predict_sample(self, np.ndarray[np.float32_t, ndim=1] sample, object tree):\n",
        "        cdef int feature\n",
        "        cdef float threshold\n",
        "        cdef object left_tree, right_tree\n",
        "        if isinstance(tree, tuple):\n",
        "            feature = tree[0]\n",
        "            threshold = tree[1]\n",
        "            left_tree = tree[2]\n",
        "            right_tree = tree[3]\n",
        "            if sample[feature] <= threshold:\n",
        "                return self._predict_sample(sample, left_tree)\n",
        "            else:\n",
        "                return self._predict_sample(sample, right_tree)\n",
        "        else:\n",
        "            return tree\n",
        "\n",
        "    def score(self, X, y):\n",
        "        return accuracy_score(np.array(y), self.predict(np.array(X)))\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with open('decision_tree.pyx', 'w') as f:\n",
        "    f.write(cython_code)\n",
        "\n",
        "setup_code = \"\"\"\n",
        "from setuptools import setup\n",
        "from Cython.Build import cythonize\n",
        "import numpy\n",
        "\n",
        "setup(\n",
        "    ext_modules=cythonize(\"decision_tree.pyx\"),\n",
        "    include_dirs=[numpy.get_include()]\n",
        ")\n",
        "\"\"\"\n",
        "\n",
        "with open('setup.py', 'w') as f:\n",
        "    f.write(setup_code)"
      ],
      "metadata": {
        "id": "yJ_vjPjGTLXZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!python setup.py build_ext --inplace\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from decision_tree import CustomDecisionTreeClassifier\n",
        "train_data = pd.read_csv('/content/train.csv', encoding='latin-1')\n",
        "test_data = pd.read_csv('/content/test.csv', encoding='latin-1')\n",
        "\n",
        "print(\"Train Data Length:\", len(train_data))\n",
        "print(\"Test Data Length:\", len(test_data))\n",
        "\n",
        "print(\"Train Data:\")\n",
        "print(train_data.head())\n",
        "print(\"\\nTest Data:\")\n",
        "print(test_data.head())\n",
        "X_train=pd.DataFrame()\n",
        "X_train = train_data.drop('price_range', axis=1)\n",
        "y_train = train_data['price_range']\n",
        "\n",
        "X_test = test_data.drop('id', axis=1)\n",
        "test_id = test_data['id']\n",
        "\n",
        "print(\"Unique values in y_train:\", pd.unique(y_train))\n",
        "mapping = {0: 0, 1: 1, 2: 1, 3: 0}\n",
        "y_train_mapped = y_train.map(mapping).astype(int)\n",
        "\n",
        "num_particles = 20\n",
        "max_iter = 100\n",
        "w = 0.5\n",
        "c1 = 2\n",
        "c2 = 2\n",
        "\n",
        "def initialize_particles(num_particles, num_features):\n",
        "    return np.random.choice([0, 1], size=(num_particles, num_features))\n",
        "\n",
        "def fitness(particle, X_train, y_train_mapped):\n",
        "\n",
        "    selected_features = X_train.columns[particle == 1]\n",
        "    if selected_features.empty:\n",
        "        return 0\n",
        "    X_train_selected = X_train[selected_features]\n",
        "    dt_classifier = CustomDecisionTreeClassifier()\n",
        "    dt_classifier.fit(X_train_selected.values, y_train_mapped)\n",
        "    accuracy = dt_classifier.score(X_train_selected.values, y_train_mapped)\n",
        "    return accuracy\n",
        "\n",
        "def update_particle(particle, velocity, best_particle, global_best_particle):\n",
        "    r1, r2 = np.random.random(size=2)\n",
        "    velocity = w * velocity + c1 * r1 * (best_particle - particle) + c2 * r2 * (global_best_particle - particle)\n",
        "    particle = np.where(np.random.random(len(particle)) < 1 / (1 + np.exp(-velocity)), 1, 0)\n",
        "    return particle, velocity\n",
        "\n",
        "def pso_feature_selection(X_train, y_train_mapped, X_test):\n",
        "    num_features = X_train.shape[1]\n",
        "    particles = initialize_particles(num_particles, num_features)\n",
        "    velocity = np.zeros((num_particles, num_features))\n",
        "    global_best_particle = particles[0]\n",
        "    global_best_fitness = fitness(global_best_particle, X_train, y_train_mapped)\n",
        "    best_particles = particles.copy()\n",
        "\n",
        "    for _ in range(max_iter):\n",
        "        for i, particle in enumerate(particles):\n",
        "            particle_fitness = fitness(particle, X_train, y_train_mapped)\n",
        "            if particle_fitness > global_best_fitness:\n",
        "                global_best_fitness = particle_fitness\n",
        "                global_best_particle = particle.copy()\n",
        "            if particle_fitness > fitness(best_particles[i], X_train, y_train_mapped):\n",
        "                best_particles[i] = particle.copy()\n",
        "        for i, particle in enumerate(particles):\n",
        "            particles[i], velocity[i] = update_particle(particle, velocity[i], best_particles[i], global_best_particle)\n",
        "\n",
        "    selected_features = X_train.columns[global_best_particle == 1]\n",
        "    X_test_selected = X_test[selected_features]\n",
        "    return selected_features, X_test_selected\n",
        "\n",
        "selected_features_train, X_test_selected = pso_feature_selection(X_train, y_train_mapped, X_test)\n",
        "\n",
        "X_train_selected = X_train[selected_features_train].values.astype(float)\n",
        "X_test_selected = X_test_selected.values.astype(float)\n",
        "y_train = y_train_mapped.values.astype(int)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CWC6iIZBTOuo",
        "outputId": "f0ac2eaa-ea66-4a51-9ba9-172637535cfd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Compiling decision_tree.pyx because it changed.\n",
            "[1/1] Cythonizing decision_tree.pyx\n",
            "/usr/local/lib/python3.10/dist-packages/Cython/Compiler/Main.py:381: FutureWarning: Cython directive 'language_level' not set, using '3str' for now (Py3). This has changed from earlier releases! File: /content/decision_tree.pyx\n",
            "  tree = Parsing.p_module(s, pxd, full_module_name)\n",
            "running build_ext\n",
            "building 'decision_tree' extension\n",
            "creating build\n",
            "creating build/temp.linux-x86_64-cpython-310\n",
            "x86_64-linux-gnu-gcc -Wno-unused-result -Wsign-compare -DNDEBUG -g -fwrapv -O2 -Wall -g -fstack-protector-strong -Wformat -Werror=format-security -g -fwrapv -O2 -fPIC -I/usr/local/lib/python3.10/dist-packages/numpy/core/include -I/usr/include/python3.10 -c decision_tree.c -o build/temp.linux-x86_64-cpython-310/decision_tree.o\n",
            "In file included from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/numpy/core/include/numpy/ndarraytypes.h:1929\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/numpy/core/include/numpy/ndarrayobject.h:12\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/numpy/core/include/numpy/arrayobject.h:5\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[Kdecision_tree.c:1240\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/numpy/core/include/numpy/npy_1_7_deprecated_api.h:17:2:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K#warning \"Using deprecated NumPy API, disable it with \" \"#define NPY_NO_DEPRECATED_API NPY_1_7_API_VERSION\" [\u001b[01;35m\u001b[K\u001b]8;;https://gcc.gnu.org/onlinedocs/gcc/Warning-Options.html#index-Wcpp\u0007-Wcpp\u001b]8;;\u0007\u001b[m\u001b[K]\n",
            "   17 | #\u001b[01;35m\u001b[Kwarning\u001b[m\u001b[K \"Using deprecated NumPy API, disable it with \" \\\n",
            "      |  \u001b[01;35m\u001b[K^~~~~~~\u001b[m\u001b[K\n",
            "creating build/lib.linux-x86_64-cpython-310\n",
            "x86_64-linux-gnu-gcc -shared -Wl,-O1 -Wl,-Bsymbolic-functions -Wl,-Bsymbolic-functions -g -fwrapv -O2 build/temp.linux-x86_64-cpython-310/decision_tree.o -L/usr/lib/x86_64-linux-gnu -o build/lib.linux-x86_64-cpython-310/decision_tree.cpython-310-x86_64-linux-gnu.so\n",
            "copying build/lib.linux-x86_64-cpython-310/decision_tree.cpython-310-x86_64-linux-gnu.so -> \n",
            "Train Data Length: 2000\n",
            "Test Data Length: 1000\n",
            "Train Data:\n",
            "   battery_power  blue  clock_speed  dual_sim  fc  four_g  int_memory  m_dep  \\\n",
            "0            842     0          2.2         0   1       0           7    0.6   \n",
            "1           1021     1          0.5         1   0       1          53    0.7   \n",
            "2            563     1          0.5         1   2       1          41    0.9   \n",
            "3            615     1          2.5         0   0       0          10    0.8   \n",
            "4           1821     1          1.2         0  13       1          44    0.6   \n",
            "\n",
            "   mobile_wt  n_cores  ...  px_height  px_width   ram  sc_h  sc_w  talk_time  \\\n",
            "0        188        2  ...         20       756  2549     9     7         19   \n",
            "1        136        3  ...        905      1988  2631    17     3          7   \n",
            "2        145        5  ...       1263      1716  2603    11     2          9   \n",
            "3        131        6  ...       1216      1786  2769    16     8         11   \n",
            "4        141        2  ...       1208      1212  1411     8     2         15   \n",
            "\n",
            "   three_g  touch_screen  wifi  price_range  \n",
            "0        0             0     1            1  \n",
            "1        1             1     0            2  \n",
            "2        1             1     0            2  \n",
            "3        1             0     0            2  \n",
            "4        1             1     0            1  \n",
            "\n",
            "[5 rows x 21 columns]\n",
            "\n",
            "Test Data:\n",
            "   id  battery_power  blue  clock_speed  dual_sim  fc  four_g  int_memory  \\\n",
            "0   1           1043     1          1.8         1  14       0           5   \n",
            "1   2            841     1          0.5         1   4       1          61   \n",
            "2   3           1807     1          2.8         0   1       0          27   \n",
            "3   4           1546     0          0.5         1  18       1          25   \n",
            "4   5           1434     0          1.4         0  11       1          49   \n",
            "\n",
            "   m_dep  mobile_wt  ...  pc  px_height  px_width   ram  sc_h  sc_w  \\\n",
            "0    0.1        193  ...  16        226      1412  3476    12     7   \n",
            "1    0.8        191  ...  12        746       857  3895     6     0   \n",
            "2    0.9        186  ...   4       1270      1366  2396    17    10   \n",
            "3    0.5         96  ...  20        295      1752  3893    10     0   \n",
            "4    0.5        108  ...  18        749       810  1773    15     8   \n",
            "\n",
            "   talk_time  three_g  touch_screen  wifi  \n",
            "0          2        0             1     0  \n",
            "1          7        1             0     0  \n",
            "2         10        0             1     1  \n",
            "3          7        1             1     0  \n",
            "4          7        1             0     1  \n",
            "\n",
            "[5 rows x 21 columns]\n",
            "Unique values in y_train: [1 2 3 0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "class CustomDecisionTreeClassifier:\n",
        "    def __init__(self, max_depth=3):\n",
        "        self.max_depth = max_depth\n",
        "        self.tree = None\n",
        "\n",
        "    def fit(self, X, y):\n",
        "        self.tree = self._build_tree(np.array(X, dtype=np.float32), np.array(y, dtype=np.int32))\n",
        "\n",
        "    def _build_tree(self, X, y, depth=0):\n",
        "        if depth == self.max_depth or len(np.unique(y)) == 1:\n",
        "            return np.bincount(y).argmax()\n",
        "        best_feature, best_threshold = self._find_best_split(X, y)\n",
        "        if best_feature == -1:\n",
        "            return np.bincount(y).argmax()\n",
        "\n",
        "        left_indices = X[:, best_feature] <= best_threshold\n",
        "        right_indices = X[:, best_feature] > best_threshold\n",
        "\n",
        "        left_tree = self._build_tree(X[left_indices], y[left_indices], depth + 1)\n",
        "        right_tree = self._build_tree(X[right_indices], y[right_indices], depth + 1)\n",
        "        return (best_feature, best_threshold, left_tree, right_tree)\n",
        "\n",
        "    def _find_best_split(self, X, y):\n",
        "        best_feature = -1\n",
        "        best_threshold = -1.0\n",
        "        best_gini = float('inf')\n",
        "        m, n = X.shape\n",
        "        num_classes = len(np.unique(y))\n",
        "\n",
        "        total_class_count = np.bincount(y, minlength=num_classes).astype(np.int64)\n",
        "        left_class_count = np.zeros(num_classes, dtype=np.int64)\n",
        "        right_class_count = total_class_count.copy()\n",
        "\n",
        "        for feature in range(n):\n",
        "            sorted_indices = np.argsort(X[:, feature])\n",
        "            sorted_X = X[sorted_indices, feature]\n",
        "            sorted_y = y[sorted_indices]\n",
        "\n",
        "            left_class_count[:] = 0\n",
        "            right_class_count[:] = total_class_count\n",
        "            total_left = 0\n",
        "            total_right = m\n",
        "\n",
        "            for i in range(1, m):\n",
        "                c = sorted_y[i - 1]\n",
        "                left_class_count[c] += 1\n",
        "                right_class_count[c] -= 1\n",
        "                total_left += 1\n",
        "                total_right -= 1\n",
        "\n",
        "                if sorted_X[i] == sorted_X[i - 1]:\n",
        "                    continue\n",
        "\n",
        "                gini_left = 1.0 - np.sum((left_class_count / total_left) ** 2)\n",
        "                gini_right = 1.0 - np.sum((right_class_count / total_right) ** 2)\n",
        "                gini = (total_left * gini_left + total_right * gini_right) / m\n",
        "\n",
        "                if gini < best_gini:\n",
        "                    best_gini = gini\n",
        "                    best_feature = feature\n",
        "                    best_threshold = (sorted_X[i] + sorted_X[i - 1]) / 2\n",
        "\n",
        "        return best_feature, best_threshold\n",
        "\n",
        "    def predict(self, X):\n",
        "        return np.array([self._predict_sample(sample, self.tree) for sample in np.array(X, dtype=np.float32)])\n",
        "\n",
        "    def _predict_sample(self, sample, tree):\n",
        "        if isinstance(tree, tuple):\n",
        "            feature, threshold, left_tree, right_tree = tree\n",
        "            if sample[feature] <= threshold:\n",
        "                return self._predict_sample(sample, left_tree)\n",
        "            else:\n",
        "                return self._predict_sample(sample, right_tree)\n",
        "        else:\n",
        "            return tree\n",
        "\n",
        "    def score(self, X, y):\n",
        "        return accuracy_score(np.array(y), self.predict(np.array(X)))\n"
      ],
      "metadata": {
        "id": "BPPKIvaWTwI2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from scipy.linalg import eigh\n",
        "import sympy as sp\n",
        "import numpy as np\n",
        "def calculate_eigenvalues(cov_matrix):\n",
        "    x = sp.symbols('x')\n",
        "    lamda_mat = sp.eye(*cov_matrix.shape) * x\n",
        "    result_matrix = lamda_mat - cov_matrix\n",
        "    determinant = sp.Matrix(result_matrix).det()\n",
        "    eigenvalues = sp.solve(determinant, x)\n",
        "    eigenvalues = np.array(eigenvalues)\n",
        "    return eigenvalues\n",
        "\n",
        "def calculate_eigenvectors(cov_matrix):\n",
        "    _, eigenvectors = np.linalg.eigh(cov_matrix)\n",
        "    return eigenvectors\n",
        "\n",
        "class LDA:\n",
        "    def __init__(self, n_components=None):\n",
        "        self.n_components = n_components\n",
        "\n",
        "    def fit(self, X, y):\n",
        "        n_samples, n_features = X.shape\n",
        "        classes, cls_counts = np.unique(y, return_counts=True)\n",
        "        priors = cls_counts / n_samples # nesba bta3t kol class\n",
        "\n",
        "        X_cls_mean = np.array([X[y == cls].mean(axis=0) for cls in classes]) # mean of features of each class\n",
        "        between_cls_deviation = X_cls_mean - X.mean(axis=0) # mean of each class - mean of whole data\n",
        "\n",
        "        within_cls_deviation = np.zeros_like(X)\n",
        "        for cls_idx, cls in enumerate(classes):\n",
        "            indices = np.where(y == cls)[0]\n",
        "            within_cls_deviation[indices] = X[indices] - X_cls_mean[cls_idx]  # subs each sample from its class mean\n",
        "\n",
        "        Sb = priors * between_cls_deviation.T @ between_cls_deviation # how far are classes to the big mean\n",
        "        Sw = within_cls_deviation.T @ within_cls_deviation / n_samples # how tight each class is\n",
        "        evals, evecs = eigh(Sb, Sw)  # eigen values and vectors\n",
        "        self.dvecs = evecs[:, np.argsort(evals)[::-1]]   # sort\n",
        "\n",
        "        if self.n_components is None:\n",
        "            self.n_components = min(classes.size - 1, n_features)\n",
        "\n",
        "\n",
        "\n",
        "    def transform(self, X):\n",
        "        return X @ self.dvecs[:, : self.n_components]\n"
      ],
      "metadata": {
        "id": "bRVKbEPYvDMQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def compute_statistical_features(X_train):\n",
        "    if len(X_train) == 0:\n",
        "        print(\"Error: Empty input data.\")\n",
        "        return None\n",
        "\n",
        "    mean = np.mean(X_train, axis=1)\n",
        "    std_dev = np.std(X_train, axis=1)\n",
        "    median = np.median(X_train, axis=1)\n",
        "    min= np.min(X_train,axis=1)\n",
        "    max=np.max(X_train,axis=1)\n",
        "    features = np.column_stack((mean, std_dev, median,min,max))\n",
        "    feature_names = ['mean', 'std_dev', 'median','minimum','maximum']\n",
        "\n",
        "    return pd.DataFrame(features, columns=feature_names)\n",
        "\n",
        "\n",
        "X_train_features = compute_statistical_features(X_train)\n",
        "\n",
        "test_features = compute_statistical_features(X_test)\n",
        "\n",
        "selected_features_train, test_features_selected = pso_feature_selection(X_train_features, y_train_mapped, test_features)\n",
        "\n"
      ],
      "metadata": {
        "id": "G5IRnP6Tyo3f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import math\n",
        "X_train_selected = X_train_features[selected_features_train].values\n",
        "X_test_selected = test_features_selected.values\n",
        "lda = LDA(n_components=2)\n",
        "lda.fit(X_train_selected, y_train_mapped)\n",
        "X_train_lda = lda.transform(X_train_selected)\n",
        "X_test_lda = lda.transform(X_test_selected)\n",
        "\n",
        "model = CustomDecisionTreeClassifier(max_depth=21)\n",
        "model.fit(X_train_lda, y_train)\n",
        "\n",
        "y_pred_train = model.predict(X_train_lda)\n",
        "\n",
        "def accuracy(y_true, y_pred):\n",
        "    return np.mean(y_true == y_pred)\n",
        "\n",
        "train_accuracy = accuracy(y_train, y_pred_train)\n",
        "print(f\"Training Accuracy: {train_accuracy:.2f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RIbrGNPvvu1N",
        "outputId": "104547f6-18a2-4ea3-ebcd-fd9030288552"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Accuracy: 0.97\n"
          ]
        }
      ]
    }
  ]
}